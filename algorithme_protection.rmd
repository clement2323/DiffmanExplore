---
title: "Diffman tutorial"
author: "Clément G"
date: "`r Sys.Date()`"
output:
  prettydoc::html_pretty:
    theme: cayman
    highlight: github
    toc: true
    toc_depth: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

mc cp s3/cguillo/commune_franceentiere_2021.dbf ext_data/commune_franceentiere_2021.dbf
mc cp s3/cguillo/commune_franceentiere_2021.fix ext_data/commune_franceentiere_2021.fix
mc cp s3/cguillo/commune_franceentiere_2021.prj ext_data/commune_franceentiere_2021.prj
mc cp s3/cguillo/commune_franceentiere_2021.shp ext_data/commune_franceentiere_2021.shp
mc cp s3/cguillo/commune_franceentiere_2021.shx ext_data/commune_franceentiere_2021.shx
mc cp s3/cguillo/data_rp.rds ext_data/data_rp.rds
mc cp s3/cguillo/data_rp.rds DiffmanExplore/data_rp.rds
mc cp s3/cguillo/resultat_brut_gridy_individus.RData resultat_brut_gridy_individus.RData
mc cp recursive s3/cguillo/diff_info 

mc cp recursive s3/cguillo/diff_info 

## Intro 
Ici, j'applique directement l'algorithme de protection sur les carreaux sensibles détectés par griddy

```{r}
paquets <- c("data.table","prettydoc","devtools","testthat","ggplot2","dplyr","btb")
```

```{r warning=FALSE,message=FALSE,echo = FALSE}
install.packages(paquets)
```

```{r warning=FALSE,message=FALSE,echo = FALSE}
p <- lapply(paquets, function(p) suppressPackageStartupMessages(library(p, character.only = TRUE)))
```

```{r, echo = FALSE}
source("fonctions_utiles.R")

remove.packages("diffman")  
devtools::install_github(
  repo = "InseeFrLab/diffman-1",
  ref = "diffmanTab",# la branche
  force = TRUE
  )

library(diffman)
```


## Détail de l'algorithme :

Ici on va utiliser les sorties de diffman sur le niveau le plus fin pour protéger les carreaux.
Diffman extrait les intersections carreaux x commune à risque, il faut donc les protéger. Pour ce faire on va blanchir des carreaux supplémentaires.

Une intersection carreau x commune donnée peut être retrouvée via différenciation externe ou interne. Ainsi on devra blanchir des carreaux (la somme des carreaux blanchis doit faire au moins 11) dans la zone interne en question et aussi dans la zone externe en question (a priori le complémentaire de la zone interne dans la composante connexe elle inclut le carreau intersectant).
(le raisonnement sur la zone externe n'est peut etre pas suffisant)

On travaille composante connexe par composante connexe. Pour la plus grosse composante connexe, cette opération prend beaucoup de temps..(10 h approximativement ).

Une fois cette protection au niveau le plus fin effectuée il faut sassurer que l'on ne peut pas reconstruire une zone interne ou externe à problème avec la juxtaposition de carreau au niveau le plus grossier. Par exemple 1 carreau de niveau 2km = 4 carreaux de niveau 1 km. donc on va vé"riifier si on a 4 carreaux ou un multiple de 4 dans la zone en question. Si oui on vérifie que 
ncarreaux / 4 = nombre d'id'entifiants uniques et que ces carreaux n'apparaissent que dans la zone en question.. (couteux..)

Ne pas travailler sur la grosse composante pour commencer !

*Ce qu'il faut regarder à la fin :*

le nombre de carreaux blanchis en + par rapport à griddy -> griddy nous donne déjà des carreaux blanchis < au seuil donc on a des chances que ces derniers soient également choisis par diffman et que la protectiion des inter carreaux x commune à risque ne coute pas beaucoup plus

le nombre de fois où on peut reconstruire intégralement une zone interne ou externe problématique à l'aide de la concaténation des carreaux supras.  

**Lecture des sorties diffman**

## Chargement des données

```{r}
source("fonctions_utiles.R")
```

```{r}
communes <-sf::st_read("ext_data/commune_franceentiere_2021.shp")
data_rp <- data.table(readRDS("ext_data/data_rp.rds"))
input_dt <- data_rp
input_dt <- clean_init_dt(input_dt)

compo <- return_connected_components(data_rp)
comp_to_nb_com <- compo[,.(nb_com = length(z1)),by ="id_comp"][rev(order(nb_com)),]
comp_to_nb_com

```

## Travail sur une composante :
On va regarder dans la composante 387 et ses 80 communes :

```{r}
load("resultat_brut_gridy_individus.RData")

carreaux_griddy <- tab_GS$tab_car
emboitement <- tab_GS$tab_arb # contient les liens vers les niveux suivants, le niveau 6 est le niveau le plus fin après le noiveau "petit"

z2_to_tag_global <- carreaux_griddy[niveau == 7][,c("id_carreau","etat","nb_obs")]
colnames(z2_to_tag_global)<- c("z2","tag","nb_obs")
z2_to_tag_global[,tag:= !tag]
head(z2_to_tag_global)
```

```{r}

all_component_risk_extraction(
  input_dt,
  threshold = 11,
  max_agregate_size = 15,
  save_dir = "diff_info"
  )


```

```{r}
global_diff_info <- read_diff_info("diff_info")
global_diff_info <- global_diff_info[!is.na(nb_obs)]
global_diff_info$checked_area_size <- sapply(strsplit(global_diff_info$checked_area,"-"),length)
summary(global_diff_info$checked_area_size)
```

Représentation graphique
```{r}
num_comp <- 263
threshold <- 11
list_z1 <- compo$z1[compo$id_comp == num_comp ]
comp_diff_info <- global_diff_info[id_comp == num_comp ]

# application de l'algo
z2_to_tag <- protect_component(
  num_comp = num_comp,
  global_diff_info = global_diff_info,
  data_rp = data_rp,
  z2_to_tag = z2_to_tag_global,
  threshold =11, checked_area_max_size = 3
  )
list_z1 <- compo[id_comp == num_comp]$z1

input_dt <- clean_init_dt(data_rp[z1 %in% list_z1])
l<- preparer_geom(input_dt)

draw_situation(
  input_dt,
  l$geom_z1,
  l$geom_z2,
  threshold = 11,
  list_z2_to_color = z2_to_tag[tag == TRUE]$z2  
               ) 
```

## Application protection post griddy

On va prendre les résultats de griddy sur les petits carreaux de julien en apriori, par exemple dans z2_to_tag et on va poser le secreten fonction en gardant le même algorithme, si ce n'est que l'on va limiter la protection aux problèmes de différenciation de taille n avec n ==...

Truc intéressant : regarder la distribution de la taille des checked area en termes de nombre de z1


```{r}
# Ok limiter le taf aux zones interne <5 et ne pas blanchir dans les zones externes trop grand n_compo- n_zone externe < 5 "moyen raisonnable"
# faire partir le code de z2_to_tag qui vient de griddy
# intégrer l'extraction des zones full_incl etc..


```

Pour la suite. : il semble y a voir beaucoup trop de cas où on peut reconstruire une zone interne ou externe avec une somme de carreaux de niveau supérieur !!

## Application de l'algo sur le data set entier :

D'abord la composante numéro 1 toute seule (tourne en 10 h..)
(cf 10000 zones à checker 1.5 secondes par zones = 15000 sec )


Puis les autres (beaucoup plus rapide..)


```{r}
install.packages("pbapply")
library(pbapply)

# 10 min
proteger_diffman <- function(max_size){
  Sys.time()
  print(max_size)
  l <- pblapply(rev(comp_to_nb_com$id_comp),function(num_comp){
    # num_comp <- 263
    #print(num_comp)
    protect_component(
    num_comp = num_comp,
    global_diff_info = global_diff_info,
    data_rp = data_rp,
    z2_to_tag_global = z2_to_tag_global,
    checked_area_max_size = max_size)
  }
  )

  res <-do.call(rbind,l)

  saveRDS(res,paste0("z2_to_tag_",max_size,".rds"))
  Sys.time()
  # z2_to_tag <- readRDS(file = "z2_to_tag.rds")
}
sapply(seq(2:5),proteger_diffman)


```
TODO : BIEN DIFFERENCIER LES CARREAUX GRIDDY DES CARREAUX NON GRIDDY DANS LES RER2SENTATIONS ?
```{r}
z2_to_tag <-
z2_to_nb_obs <- clean_init_dt(data_rp)[,.(nb_obs = sum(nb_obs)), by  = "z2"]
z2_to_tag_obs <- merge(z2_to_tag,z2_to_nb_obs,by = "z2")

z2_to_tag_obs[tag == TRUE & nb_obs >11]

z2_sup_seuil <- z2_to_tag_obs[tag == TRUE & nb_obs >11]$z2 #2343

carreaux_griddy[id_carreau %in% z2_sup_seuil] %>% 
  group_by(etat) %>% 
  summarise(compte = n()) # 1053 protégés par griddy déjà ..

```

```{r}

# petit test d'algo 
emboitement <- emboitement %>% 
  group_by(z2_sup) %>% 
  mutate(nfils = n()) 

  area_issue <- global_diff_info$checked_area[1]  
  
  # comp_to_nb_com
  num_comp <- 22
  list_z1_compo<- compo$z1[compo$id_comp == num_comp]
  
  dt <- copy(data_rp)
  input_dt <- clean_init_dt(dt[z1 %in% list_z1_compo])
  
  comp_diff_info <- global_diff_info[id_comp == num_comp]
  complete_internal_diff_info <- build_complete_internal_table(comp_diff_info,list_z1_compo)
  
  l <- split(complete_internal_diff_info, complete_internal_diff_info$checked_area)
  
  ## on fait une check area
  area_issue <- l[[1]]
  # je construis
  
  fully_included_z2<- diffman:::prepare_data(input_dt)$fully_included_z2
  z2_to_tag$full_incl <- z2_to_tag$z2 %in% unique(fully_included_z2$z2)
  
  
  if(nrow(comp_diff_info)==0) return(NULL)  # Je build ici la table avectoutes les internal différences
  


```


```{r}
# récupération du nombre d'individus par z2 ?
z2_to_nb_obs <- clean_init_dt(data_rp)[,.(nb_obs = sum(nb_obs)), by  = "z2"]
z2_to_tag_obs <- merge(z2_to_tag,z2_to_nb_obs,by = "z2")
z2_to_tag_obs[tag == TRUE & nb_obs >11]
z2_sup_seuil <- z2_to_tag_obs[tag == TRUE & nb_obs >11]$z2
```


```{r}



# controle même nombre de ménages par carreaux 
# z2_test <- input_dt[,.(nb_obs = sum(nb_obs)), by = "z2"]
# merge(z2_to_tag,z2_test,by.x = "id_carreau",by.y = "z2")[nb_obs.x != nb_obs.y]
#[,.(nb_obs = sum(nb_obs)), by = "z2"]

# emboitement <- emboitement[,c("id_carreau_petit","id_carreau_niv6")]
# colnames(emboitement)<- c("z2","z2_sup")
# 
# carreaux_griddy[id_carreau %in% z2_sup_seuil] # ici un seul des deux est effectivement blanchi par griddy.

```